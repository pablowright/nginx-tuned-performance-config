
# This config 07-13-2018:
# PRW: MODIFICATIONS tuning NGINX performance for sending out STB updates. Notes and mods added by -prw 06-2018:
# After making changes restart nginx: 'systemctl stop|start|restart nginx'
# Also set these:
# set SELinux boolean httpd_setrlimit to true
# This will set fd limits for the worker processes and allow the worker_rlimit_nofile directive in /etc/nginx/nginx.conf to actually have an effect.
# and run the following as root:
#    setsebool -P httpd_setrlimit 1
#   Show current limit on master process:
#    cat /proc/$(cat /var/run/nginx.pid)/limits|grep open.files
#   Show current limit on worker processes:
#     ps --ppid $(cat /var/run/nginx.pid) -o %p|sed '1d'|xargs -I{} cat /proc/{}/limits|grep open.files
#
# You will need to make changes in '/etc/sysctl.conf' as noted. See attached sysctl.conf for examples.
# You will need to make changes in '/etc/sysctl.conf' as noted. See attached sysctl.conf for examples.
# Run # sysctl -p to refresh with the new configuration in sysctl.conf
#
# ===== Updated: Perhaps a better approach would be to increase the limit on the master process as well as the child processes.
#  The selinux change just increases the liimts on the child processes:
#
#    mkdir /etc/systemd/system/nginx.service.d
#    Add following to /etc/systemd/system/nginx.service.d/nofile_limit.conf:
#    
#    [Service]
#    LimitNOFILE=200000
#
#  Reload systemd daemon configuration and restart nginx:
#
#      systemctl daemon-reload
#      systemctl restart nginx.service (or 'systemctl stop|start|restart nginx')
#
# At some point you start to run into network card limitations before you bump up against NGINX limits.
# Confirming that your O/S is taking advantage of multithreading network Tx/Rx is a good place to start:
#     cat /proc/interrupts |grep ens160 <===name of NIC
#     ls /sys/class/net/ens160/queues/
#     returns: rx-0  rx-1  rx-2  rx-3  tx-0  tx-1  tx-2  tx-3 on a server with four processors configured for multiqueue
#

# ======== Begin nginx configuration: ====

user  nginx;

# PRW: default value:
# worker_processes  1;
# PRW MOD: Set it to the number of CPUs [CONSERVATIVE] (4 on THIS server) or let NGINX calculate it automatically.
# NGINX will set this number to 4 (number of CPUs) if set to auto:
worker_processes  auto;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

# PRW: Changes the limit on the maximum number of open files (RLIMIT_NOFILE) for worker processes:
# If this is not set, the OS settings will be used which is 1024 by default. Based on "worker_connections" directive settings
# you may receive: "nginx: [warn] 4000 worker_connections exceed open file resource limit: 1024" warning message if you do not
# adjust this number. N.B. ALSO DO THIS IF YOU USE SELINUX: as root: 'setsebool -P httpd_setrlimit 1'
# If you take the "nofile_limit.conf" approach, comment this out:
#
# worker_rlimit_nofile 100000;
# Even more. PRW
# worker_rlimit_nofile 200000;


events {
    # PRW: Determines how many clients will be served per worker
    # max clients = worker_connections * worker_processes
    # max clients is also limited by the number of socket connections available on the system (~64k)

    worker_connections 65535;

    # PRW: For this server/config: 4 worker_processes * 65535 worker_connections = 262140 clients per second.

    # Let each process accept multiple connections.
    # Accept as many connections as possible, after nginx gets notification
    # about a new connection.
    # May flood worker_connections, if that option is set too low.
    #
    multi_accept on;

    #
    # Preferred connection method for newer linux versions.
    # Essential for linux, optmized to serve many clients with each thread.
    #
    use epoll;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main buffer=32k;
    # PRW: we could boost I/O on the HDDs if we  disable access logging:
    # access_log off;

    # Override some buffer limitations, will prevent DDOS too.
    #
    # client_body_buffer_size 10K;
    # client_header_buffer_size 1k;
    # client_max_body_size 8m;
    # large_client_header_buffers 2 1k;


    # PRW: Default for 'sendfile' is 'on'
    sendfile        on;
    
    # PRW: When set to a non-zero value, limits the amount of data that can be transferred in a single sendfile() call.
    # Without the limit, one fast connection may seize the worker process entirely.
    sendfile_max_chunk 512k;

    # PRW: Set tcp_nopush. This enables NGINX to send HTTP response headers in one packet right after the chunk of data has been obtained
    # by sendfile().
    tcp_nopush     on;
    tcp_nodelay    on;

    # PRW: Allow the server to close connection on non responding client, this will free up memory:
    reset_timedout_connection on;

    # Open file descriptors.
    # Caches information about open FDs, freqently accessed files.
    #
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # PRW: request timed out -- default 60
    client_body_timeout 20;
    client_header_timeout 20;

    # PRW: If client stops responding, free up memory -- default 60
    send_timeout 20;

    # PRW: server will close connection after this time -- default 75
    keepalive_timeout  30;

    # PRW: gzip in set to 'on' by default. Also by default, Nginx compresses only HTML files. Every other file will be served uncompressed
    # unless configured otherwise.
    # gzip  on;

    include /etc/nginx/conf.d/*.conf;

    # PRW: Tuning server for connection performance. See next note:

    server {
        listen 80 backlog=65535;
    }

}

# PRW: Optimizing the Backlog Queue: The general rule is when a connection is established, it is put into the “listen” queue of a
# listen socket.
# Under normal load, either the queue is small or there is no queue at all. But under high load, the queue can grow dramatically,
# resulting in uneven performance, dropped connections, and increased latency.
# command: 'netstat -Lan' will display the current listen queue.
#
# PRW: Tuning the Operating System:
# Increase the value of the net.core.somaxconn kernel parameter from its default value (128) to a value high enough for a large burst
# of traffic. PRW: set this value to 65535 by adding the following line to /etc/sysctl.conf: net.core.somaxconn = 65535
#
# PRW: Since somaxconn kernel parameter is now set to a value greater than 512, we need to change the backlog parameter in the
# NGINX listen directive. See 'server {' directive, above.
